{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import json\n",
    "from pymongo import MongoClient\n",
    "from bson.json_util import dumps\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONGO_HOST= 'mongodb://localhost/'  # assuming you have mongoDB installed locally\n",
    "                                             # and a database called 'twitterdb'\n",
    "client = MongoClient(MONGO_HOST)\n",
    "db = client.twitterdb\n",
    "data_lasso = db.twitter_search_lasso_after_elections\n",
    "data_arauz = db.twitter_search_arauz_after_elections\n",
    "#data_arauz_new = db.twitter_search_arauz_new "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(client,database_search):\n",
    "    columns_find = [\"created_at\",\"favorite_count\",\"full_text\",\"id_str\",\"metadata.iso_language_code\",\"retweeted_status.created_at\",\"retweeted_status.full_text\",\"user.created_at\",\"user.favourites_count\",\"user.followers_count\",\"user.friends_count\",\"user.id_str\",\"user.location\",\"user.verified\",\"retweet_count\"]\n",
    "    data = database_search.find(no_cursor_timeout=True)\n",
    "    data_tweets = None\n",
    "    cont=0\n",
    "    for tweet in data:\n",
    "        dict_values_JSON = {}\n",
    "        for column in columns_find:\n",
    "            column_splited =  column.split(\".\")\n",
    "            \n",
    "            if len(column_splited)==2:\n",
    "                if column_splited[0] in tweet:\n",
    "                    data_key = tweet[column_splited[0]]\n",
    "                    \n",
    "                    if column_splited[1] in data_key:\n",
    "                        dict_values_JSON[column] = [data_key[column_splited[1]]]\n",
    "                    else:\n",
    "                        dict_values_JSON[column] = [np.nan]\n",
    "                else:\n",
    "                    dict_values_JSON[column] = [np.nan]\n",
    "            else:\n",
    "                if column_splited[0] in tweet:\n",
    "                    dict_values_JSON[column] = [tweet[column]]\n",
    "                else:\n",
    "                    dict_values_JSON[column] = [np.nan]\n",
    "\n",
    "        if cont==0:\n",
    "            data_tweets=pd.DataFrame(dict_values_JSON)\n",
    "        else:\n",
    "            df_auxiliar = pd.DataFrame(dict_values_JSON)\n",
    "            data_tweets = pd.concat([data_tweets, df_auxiliar], axis=0)\n",
    "            data_tweets = data_tweets.reset_index(drop=True)\n",
    "        cont+=1\n",
    "    return data_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_lasso = extract_data(client,data_lasso)\n",
    "df_tweets_lasso.to_csv(\"tweets_lasso_after_elections.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_tweets_lasso.to_csv(\"Twitter_search_Lasso.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_tweets_lasso_new = extract_data(client,data_lasso_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_tweets_lasso_new.to_csv(\"Twitter_search_Lasso_new.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_arauz = extract_data(client,data_arauz)\n",
    "df_tweets_arauz.to_csv(\"tweets_arauz_after_elections.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_tweets_arauz.to_csv(\"Twitter_search_Arauz.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_tweets_arauz_new = extract_data(client,data_arauz_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_tweets_arauz_new.to_csv(\"Twitter_search_Arauz_new.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_tweets = pd.concat([df_tweets_lasso, df_tweets_arauz], axis=0)\n",
    "#data_tweets = data_tweets.reset_index(drop=True)\n",
    "#data_tweets.to_csv(\"twitter_calidad.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}